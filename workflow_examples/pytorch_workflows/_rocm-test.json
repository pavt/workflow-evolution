{
  "name": "test",
  "on": {
    "workflow_call": {
      "inputs": {
        "build-environment": {
          "required": true,
          "type": "string",
          "description": "Top-level label for what's being built/tested."
        },
        "test-matrix": {
          "required": true,
          "type": "string",
          "description": "JSON description of what test configs to run."
        },
        "docker-image": {
          "required": true,
          "type": "string",
          "description": "Docker image to run in."
        },
        "sync-tag": {
          "required": false,
          "type": "string",
          "default": "",
          "description": "If this is set, our linter will use this to make sure that every other\njob with the same `sync-tag` is identical.\n"
        }
      },
      "secrets": {
        "AWS_OSSCI_METRICS_V2_ACCESS_KEY_ID": {
          "required": true,
          "description": "access key id for test stats upload"
        },
        "AWS_OSSCI_METRICS_V2_SECRET_ACCESS_KEY": {
          "required": true,
          "description": "secret acess key for test stats upload"
        }
      }
    }
  },
  "env": {
    "GIT_DEFAULT_BRANCH": "${{ github.event.repository.default_branch }}"
  },
  "jobs": {
    "test": {
      "if": "github.repository_owner == 'pytorch'",
      "timeout-minutes": 300,
      "strategy": {
        "matrix": "${{ fromJSON(inputs.test-matrix) }}",
        "fail-fast": false
      },
      "runs-on": "${{ matrix.runner }}",
      "steps": [
        {
          "name": "Checkout PyTorch",
          "uses": "pytorch/pytorch/.github/actions/checkout-pytorch@master",
          "with": {
            "no-sudo": true
          }
        },
        {
          "name": "Setup ROCm",
          "uses": "./.github/actions/setup-rocm"
        },
        {
          "name": "Pull docker image",
          "uses": "pytorch/test-infra/.github/actions/pull-docker-image@main",
          "with": {
            "docker-image": "${{ inputs.docker-image }}"
          }
        },
        {
          "name": "Start monitoring script",
          "id": "monitor-script",
          "shell": "bash",
          "run": "python3 -m pip install psutil==5.9.1\npython3 -m pip install pynvml==11.4.1\npython3 -m tools.stats.monitor > usage_log.txt 2>&1 &\necho \"monitor-script-pid=${!}\" >> \"${GITHUB_OUTPUT}\"\n"
        },
        {
          "name": "Download build artifacts",
          "uses": "./.github/actions/download-build-artifacts",
          "with": {
            "name": "${{ inputs.build-environment }}"
          }
        },
        {
          "name": "Parse ref",
          "id": "parse-ref",
          "run": ".github/scripts/parse_ref.py"
        },
        {
          "name": "Test",
          "id": "test",
          "env": {
            "BUILD_ENVIRONMENT": "${{ inputs.build-environment }}",
            "PR_NUMBER": "${{ github.event.pull_request.number }}",
            "BRANCH": "${{ steps.parse-ref.outputs.branch }}",
            "SHA1": "${{ github.event.pull_request.head.sha || github.sha }}",
            "PYTORCH_RETRY_TEST_CASES": 1,
            "PYTORCH_OVERRIDE_FLAKY_SIGNAL": 1,
            "TEST_CONFIG": "${{ matrix.config }}",
            "SHARD_NUMBER": "${{ matrix.shard }}",
            "NUM_TEST_SHARDS": "${{ matrix.num_shards }}",
            "PR_BODY": "${{ github.event.pull_request.body }}",
            "SCCACHE_BUCKET": "ossci-compiler-cache-circleci-v2",
            "DOCKER_IMAGE": "${{ inputs.docker-image }}",
            "XLA_CLANG_CACHE_S3_BUCKET_NAME": "ossci-compiler-clang-cache-circleci-xla",
            "PYTORCH_JIT_ENABLE_NVFUSER": 1,
            "PYTORCH_TEST_CUDA_MEM_LEAK_CHECK": "${{ matrix.mem_leak_check && '1' || '0'}}"
          },
          "timeout-minutes": 270,
          "run": "set -x\n\nif [[ $TEST_CONFIG == 'multigpu' ]]; then\n  TEST_COMMAND=.jenkins/pytorch/multigpu-test.sh\nelif [[ $BUILD_ENVIRONMENT == *onnx* ]]; then\n  TEST_COMMAND=.jenkins/caffe2/test.sh\nelse\n  TEST_COMMAND=.jenkins/pytorch/test.sh\nfi\n\nCOMMIT_MESSAGES=$(git cherry -v \"origin/${GIT_DEFAULT_BRANCH:-master}\")\n\n# sanitize the input commit message and PR body here:\n#\n# trim all new lines from commit messages + PR_BODY to avoid issues with batch environment\n# variable copying. see https://github.com/pytorch/pytorch/pull/80043#issuecomment-1167796028\nCOMMIT_MESSAGES=\"${COMMIT_MESSAGES//[$'\\n\\r']}\"\nPR_BODY=\"${PR_BODY//[$'\\n\\r']}\"\n\n# then trim all special characters like single and double quotes to avoid unescaped inputs to\n# wreak havoc internally\nexport COMMIT_MESSAGES=\"${COMMIT_MESSAGES//[\\'\\\"]}\"\nexport PR_BODY=\"${PR_BODY//[\\'\\\"]}\"\n\n# detached container should get cleaned up by teardown_ec2_linux\n# TODO: Stop building test binaries as part of the build phase\n# Used for GPU_FLAG since that doesn't play nice\n# shellcheck disable=SC2086,SC2090\ncontainer_name=$(docker run \\\n  ${GPU_FLAG:-} \\\n  -e BUILD_ENVIRONMENT \\\n  -e PR_NUMBER \\\n  -e GITHUB_ACTIONS \\\n  -e BRANCH \\\n  -e SHA1 \\\n  -e AWS_DEFAULT_REGION \\\n  -e IN_WHEEL_TEST \\\n  -e SHARD_NUMBER \\\n  -e TEST_CONFIG \\\n  -e NUM_TEST_SHARDS \\\n  -e PR_BODY \\\n  -e COMMIT_MESSAGES \\\n  -e PYTORCH_RETRY_TEST_CASES \\\n  -e PYTORCH_OVERRIDE_FLAKY_SIGNAL \\\n  -e MAX_JOBS=\"$(nproc --ignore=2)\" \\\n  -e SCCACHE_BUCKET \\\n  -e XLA_CLANG_CACHE_S3_BUCKET_NAME \\\n  -e PYTORCH_TEST_CUDA_MEM_LEAK_CHECK \\\n  --env-file=\"/tmp/github_env_${GITHUB_RUN_ID}\" \\\n  --ulimit stack=10485760:83886080 \\\n  --security-opt seccomp=unconfined \\\n  --cap-add=SYS_PTRACE \\\n  --shm-size=\"8g\" \\\n  --tty \\\n  --detach \\\n  --name=\"${container_name}\" \\\n  --user jenkins \\\n  -v \"${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace\" \\\n  -w /var/lib/jenkins/workspace \\\n  \"${DOCKER_IMAGE}\"\n)\n# save container name for later step\necho \"CONTAINER_NAME=${container_name}\" >> \"$GITHUB_ENV\"\n# jenkins user does not have write permission to mounted workspace; work-around by copying within container to jenkins home\ndocker exec -t \"${container_name}\" sh -c \"cd .. && cp -R workspace pytorch && cd pytorch && pip install dist/*.whl && ${TEST_COMMAND}\"\n"
        },
        {
          "name": "Save test results",
          "if": "always()",
          "run": "# copy test results back to the mounted workspace, needed sudo, resulting permissions were correct\ndocker exec -t \"${{ env.CONTAINER_NAME }}\" sh -c \"cd ../pytorch && sudo cp -R test/test-reports ../workspace/test\"\n"
        },
        {
          "name": "Get workflow job id",
          "id": "get-job-id",
          "uses": "./.github/actions/get-workflow-job-id",
          "if": "always()",
          "with": {
            "github-token": "${{ secrets.GITHUB_TOKEN }}"
          }
        },
        {
          "name": "Stop monitoring script",
          "if": "always() && steps.monitor-script.outputs.monitor-script-pid",
          "shell": "bash",
          "continue-on-error": true,
          "env": {
            "MONITOR_SCRIPT_PID": "${{ steps.monitor-script.outputs.monitor-script-pid }}"
          },
          "run": "kill \"$MONITOR_SCRIPT_PID\"\n"
        },
        {
          "name": "Upload test artifacts",
          "uses": "./.github/actions/upload-test-artifacts",
          "if": "always() && (steps.test.conclusion == 'success' || steps.test.conclusion == 'failure')",
          "with": {
            "use-gha": true,
            "file-suffix": "${{ github.job }}-${{ matrix.config }}-${{ matrix.shard }}-${{ matrix.num_shards }}-${{ matrix.runner }}_${{ steps.get-job-id.outputs.job-id }}"
          }
        },
        {
          "name": "Upload test statistics",
          "if": "always()",
          "env": {
            "AWS_DEFAULT_REGION": "us-east-1",
            "GIT_DEFAULT_BRANCH": "${{ github.event.repository.default_branch }}",
            "BRANCH": "${{ steps.parse-ref.outputs.branch }}",
            "TEST_CONFIG": "${{ matrix.config }}",
            "SHARD_NUMBER": "${{ matrix.shard }}",
            "BUILD_ENVIRONMENT": "${{ inputs.build-environment }}",
            "PR_NUMBER": "${{ github.event.pull_request.number }}",
            "PYTORCH_RETRY_TEST_CASES": 1,
            "PYTORCH_OVERRIDE_FLAKY_SIGNAL": 1,
            "SHA1": "${{ github.event.pull_request.head.sha || github.sha }}",
            "TAG": "${{ steps.parse-ref.outputs.tag }}",
            "WORKFLOW_ID": "${{ github.run_id }}",
            "GITHUB_TOKEN": "${{ secrets.GITHUB_TOKEN }}",
            "AWS_ACCESS_KEY_ID": "${{ secrets.AWS_OSSCI_METRICS_V2_ACCESS_KEY_ID }}",
            "AWS_SECRET_ACCESS_KEY": "${{ secrets.AWS_OSSCI_METRICS_V2_SECRET_ACCESS_KEY }}",
            "GHA_WORKFLOW_JOB_ID": "${{ steps.get-job-id.outputs.job-id }}"
          },
          "shell": "bash",
          "run": "set -x\npython3 -m pip install -r requirements.txt\npython3 -m pip install boto3==1.19.12\npython3 -m tools.stats.print_test_stats --upload-to-s3 --compare-with-s3 test\n"
        },
        {
          "name": "Teardown ROCm",
          "if": "always()",
          "shell": "bash",
          "run": "# Only stop the docker container we started since there might be multiple runners on this host.\ndocker stop \"${{ env.CONTAINER_NAME }}\" || true\n# Prune all of the docker containers.\n# Might fail if a prune is already in progress by another runner.\ndocker container prune -f || true\n# Prune everything docker if there are more than 10 images (~200GB).\n# This is easier than using a time filter, e.g., \"until=24h\".\n# Might fail if a prune is already in progress by another runner.\nimage_count=$(docker images | wc -l)\nif [[ ${image_count} -gt 10 ]]; then\n    echo \"Purging all docker caches\"\n    docker system prune -af || true\nelse\n    echo \"Will not purge docker, only ${image_count} images found\"\nfi\n"
        }
      ]
    }
  }
}